exp_name: roberta
model_name: roberta-base
lr: 2.e-5
lr_step_type: 'step'
effective_batch_size: 32
negative_ratio: 1
negative_sampling_strategy: random
weight_decay: 1.e-2

resume_from: ""
out_dir: 'data'

summaries_fp: 'data/matching/with_autolabels/summaries.json'
train_fp: 'data/matching/with_autolabels/train.json'
val_fp: 'data/matching/with_autolabels/val.json'
test_fp: 'data/matching/with_autolabels/test.json'

gpu: 0
device_batch_size: 8
val_check_interval: 18432